
### Title
> Feedback-based Curriculum Learning for Collision Avoidance

### Abstract
> In this paper, we propose a novel curriculum learning for collision avoidance using feedback from the training process of deep reinforcement learning (DRL). Previous research on DRL-based collision avoidance algorithms has faced challenges such as long training time and difficulty in convergence due to sparse rewards. To address these issues, curriculum learning, which divides the target task into multiple subtasks, has been used for training. However, manual or random curriculum design tends to generate unnecessary subtasks that do not improve performance. In addition, the standardized curriculum design method for collision avoidance has not been presented. Therefore, this paper presents a curriculum-based collision avoidance learning method that utilizes feedback in the training phase. Unlike the traditional curriculum learning where the subtask is determined before training, the proposed method modifies the curriculum during training using the feedback obtained in validation environments. If a robot shows high collision avoidance performance in the validation environment, the robot is validated in more challenging validation environments for rigorous evaluation. Conversely, if the collision avoidance performance in the validation environment is low, we generate subtasks and train a robot in a new training environment aimed at overcoming situations where collisions occur frequently. We have conducted simulations and practical experiments for the proposed method, which showed better performance compared to the no curriculum method.

### Conclusion
> This paper proposes a feedback-based curriculum design method using DRL. Collision avoidance performance is evaluated in various validation environments for each training phase, which provide feedback of success or failure. This feedback provides information on which environments are difficult to avoid collisions using the current DRL model, and helps to incrementally train a robot in the appropriate training environments. In addition, the feedback allows the robot to identify shortcomings in its current level of collision avoidance; the robot can continuously improve its collision avoidance performance by designing subtasks and new training environments that take these shortcomings into account. Simulation and real-world experiments comparing models without curriculum learning show that the proposed method has an advantage in terms of generalization performance and collision avoidance performance. We will consider automated curriculum design methods to ensure performance in a wider variety of environments as future research.


### Paper
[Link](https://mail-attachment.googleusercontent.com/attachment/u/0/?ui=2&ik=1f044c8195&attid=0.1&permmsgid=msg-f:1787702301782501977&th=18cf31c595e4ea59&view=att&disp=inline&saddbat=ANGjdJ9ZFPcYVdzHc3MnoJdQhYw0xb6Ku8pasI08XEo_hoSZ0jwaKTsBvmnW61hznN7hHqkWMOHawxQVZPBSB6DaQQ12SraYd02Yy4-j0TCWdxGiZqyfPu70Fq4EG8TI4xlMLJFAbfo00tsp5kbXe2OgijBwPRebeiFJT_RSponbHUsU_rUFZmOgP6bCfPrXCUFI260EZmri6cgVKBZQe9HmLlfhtTpTIko8ZXLqqW3ikIk006IFpq_B3EJvXmNJ-j3CFPKws94unJICHJjDA1EMnYWCoq_1K5lvpp_kFxnZFKWaLknnYBbh29jZpDDLXq5xLcQ_e9OyDds2FavW15cQz4VGbahdEn4nfXxmO-1q4TcMil-AYVN7wimVu26fnI1UeIz85L12zJGlRSSGST8qR70RV6uDZrJ12rrH5KzfW_N1SzK0ANG8lvQ4oasS23L-UduInfUeo4nQP_OK-bYQeRdqv618J-xH82WrvcONLBHK-WkPMlKafIf4FydeZ8SXrM6fB6EVgwABPTha8BFa3oDJU4_sg1F_oPSpUVXukEmKvTqMaz7E_WZ8cQ6Wvb5ZAB5Tsut9WzSP5eW8LaNFYb5GXHTv0VXmxb8TGV5zaWsa7Orm5xp1dhLOrTVjFHHJlo8GvPyC1WFl6y5p3eXplt1zfqSGffWCtiguhisdEoMSO41F9oKdKXA6sXonUH9gBnOs6pAINQnWbCn4teVfFVzygJj11Jaag6nrVnve66bASVhZEVC7JRn_d3xJz47j1m1shcbQ1J6Lg-npNdoMpX7i_layFBHpUmD1K3t7segx1AkmasdU_iLN4XpE8Hsw02rY7hT-VNnwJyXC98ep1DyB-p6MidbsIwHL5Yd8IO11RSb6fHutg_MuVEhnZEvUHLvCCWtDgVhl3kCuY0aFRU2axQ-jz-2YIaCTA6w5_jvYc5ZkQ7SCzAajf9iME5GOYl8ckFPjiezBgQssrJGv7cXSEZTHvg6cM5LD5Ses22c8_-Yvc1SISOA5PUs)
